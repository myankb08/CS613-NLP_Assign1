{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install essential libraries for deep learning, model loading, and evaluation\n!pip install torch --quiet\n!pip install transformers==4.53.2 --quiet\n!pip install datasets==2.18.0 --quiet\n!pip install evaluate==0.4.1 --quiet\n!pip install sacrebleu==2.4.2 --quiet\n!pip install pandas --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:16:50.211093Z","iopub.execute_input":"2025-10-03T06:16:50.211686Z","iopub.status.idle":"2025-10-03T06:18:29.353828Z","shell.execute_reply.started":"2025-10-03T06:16:50.211660Z","shell.execute_reply":"2025-10-03T06:18:29.352858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install the custom toolkit required for IndicTrans2 pre-processing and post-processing\n!pip install indictranstoolkit --quiet","metadata":{"execution":{"iopub.status.busy":"2025-10-03T06:18:29.354985Z","iopub.execute_input":"2025-10-03T06:18:29.355318Z","iopub.status.idle":"2025-10-03T06:18:33.667958Z","shell.execute_reply.started":"2025-10-03T06:18:29.355282Z","shell.execute_reply":"2025-10-03T06:18:33.667231Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# Access the stored Hugging Face token from Kaggle Secrets\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n# Programmatically log in to Hugging Face\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:18:33.668867Z","iopub.execute_input":"2025-10-03T06:18:33.669092Z","iopub.status.idle":"2025-10-03T06:18:34.347645Z","shell.execute_reply.started":"2025-10-03T06:18:33.669069Z","shell.execute_reply":"2025-10-03T06:18:34.347093Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\n# Define the device for computation (GPU if available, otherwise CPU)\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nLANGS = [\"hin_Deva\", \"pan_Guru\", \"tam_Taml\", \"ben_Beng\", \"mar_Deva\", \"tel_Telu\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:18:34.349401Z","iopub.execute_input":"2025-10-03T06:18:34.349591Z","iopub.status.idle":"2025-10-03T06:18:37.588973Z","shell.execute_reply.started":"2025-10-03T06:18:34.349575Z","shell.execute_reply":"2025-10-03T06:18:37.588393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nMODEL_NAME = \"ai4bharat/indictrans2-indic-indic-dist-320M\"\n\n# Load the tokenizer\n# trust_remote_code is required for custom tokenization logic\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n\n# Load the model\n# trust_remote_code is required for custom model architecture\n# torch_dtype=torch.float16 uses half-precision for memory efficiency and speed\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    MODEL_NAME,\n    trust_remote_code=True,\n).to(DEVICE)\n\nmodel.eval() # Set the model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:18:37.589637Z","iopub.execute_input":"2025-10-03T06:18:37.589942Z","iopub.status.idle":"2025-10-03T06:19:05.781716Z","shell.execute_reply.started":"2025-10-03T06:18:37.589925Z","shell.execute_reply":"2025-10-03T06:19:05.781077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IndicTransToolkit.processor import IndicProcessor\n\n# Instantiate the processor for inference tasks\nip = IndicProcessor(inference=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:05.782433Z","iopub.execute_input":"2025-10-03T06:19:05.782941Z","iopub.status.idle":"2025-10-03T06:19:06.298627Z","shell.execute_reply.started":"2025-10-03T06:19:05.782921Z","shell.execute_reply":"2025-10-03T06:19:06.298032Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the 'test' split of the IN22-Gen dataset in the 'all' configuration\n# This provides a single table with all language pairs aligned by sentence ID\nin22_gen_dataset = load_dataset(\"ai4bharat/IN22-Gen\", split=\"test\")\n\n# Display the first example to inspect the structure\nprint(\"Dataset loaded. Example entry:\")\nprint(in22_gen_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:06.299374Z","iopub.execute_input":"2025-10-03T06:19:06.299586Z","iopub.status.idle":"2025-10-03T06:19:08.097706Z","shell.execute_reply.started":"2025-10-03T06:19:06.299569Z","shell.execute_reply":"2025-10-03T06:19:08.097110Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nfrom tqdm.notebook import tqdm\n\ndef translate_batch(sentences, src_lang, tgt_lang, batch_size=16):\n    translations = []\n    for i in tqdm(range(0, len(sentences), batch_size), desc=f\"Translating {src_lang} -> {tgt_lang}\"):\n        batch = sentences[i:i+batch_size]\n\n        if not batch or all(s is None or str(s).strip() == \"\" for s in batch):\n            continue\n\n        # Preprocess\n        preprocessed_batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n        if preprocessed_batch is None or len(preprocessed_batch) == 0:\n            print(f\"⚠️ Preprocessing returned None/empty for {src_lang}->{tgt_lang}\")\n            continue\n\n        # Tokenize\n        inputs = tokenizer(\n            preprocessed_batch,\n            padding=True,\n            truncation=True,\n            return_tensors=\"pt\"\n        ).to(DEVICE)\n\n        forced_bos_token_id = tokenizer.convert_tokens_to_ids(f\"<2{tgt_lang}>\")\n        \n        # Generate\n        with torch.no_grad():\n            generated_tokens = model.generate(\n                **inputs,\n                num_beams=5,\n                max_length=256,\n                forced_bos_token_id=forced_bos_token_id\n            )\n\n        # Decode\n        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\n        # Postprocess safely\n        try:\n            postprocessed = ip.postprocess_batch(decoded, lang=tgt_lang)\n            if postprocessed is None:\n                raise ValueError(\"postprocess_batch returned None\")\n        except Exception as e:\n            print(f\"⚠️ Postprocessing failed for {src_lang}->{tgt_lang}: {e}\")\n            postprocessed = decoded  # fallback\n\n        translations.extend(postprocessed)\n\n    return translations\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:08.098458Z","iopub.execute_input":"2025-10-03T06:19:08.099015Z","iopub.status.idle":"2025-10-03T06:19:08.106305Z","shell.execute_reply.started":"2025-10-03T06:19:08.098995Z","shell.execute_reply":"2025-10-03T06:19:08.105536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\ndef evaluate_direction(src_lang, tgt_lang, dataset, num_samples=200):\n    \"\"\"\n    Evaluate translation performance from src_lang -> tgt_lang\n    using chrF++ on a subset of the dataset.\n    \"\"\"\n    src_sentences = dataset[src_lang][:num_samples]\n    tgt_sentences = dataset[tgt_lang][:num_samples]\n\n    # Translate\n    preds = translate_batch(src_sentences, src_lang, tgt_lang)\n\n    # Ensure preds is a flat list of strings\n    preds = [p if isinstance(p, str) else \"\" for p in preds]\n\n    if len(preds) == 0:\n        print(f\"⚠️ No predictions produced for {src_lang}->{tgt_lang}\")\n        return None\n\n    from sacrebleu.metrics import CHRF\n    chrf = CHRF(word_order=2)  # chrF++\n    score = chrf.corpus_score(preds, [tgt_sentences]).score\n    return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:08.106934Z","iopub.execute_input":"2025-10-03T06:19:08.107129Z","iopub.status.idle":"2025-10-03T06:19:08.313453Z","shell.execute_reply.started":"2025-10-03T06:19:08.107114Z","shell.execute_reply":"2025-10-03T06:19:08.312831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pick 5 sentences for testing\nsample_src = in22_gen_dataset[\"hin_Deva\"][:5]\nsample_tgt = in22_gen_dataset[\"pan_Guru\"][:5]\n\nprint(\"RAW source examples:\", sample_src)\n\n# Step 1: Preprocess\npreprocessed = ip.preprocess_batch(sample_src, src_lang=\"hin_Deva\", tgt_lang=\"pan_Guru\")\nprint(\"\\nAfter preprocess:\", preprocessed)\n\n# Step 2: Tokenize\ninputs = tokenizer(\n    preprocessed,\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n).to(DEVICE)\n\nprint(\"\\nTokenizer output keys:\", inputs.keys())\nprint(\"Shape of input_ids:\", inputs[\"input_ids\"].shape if \"input_ids\" in inputs else \"MISSING\")\n\n# Step 3: Generate (only if inputs look good)\nif \"input_ids\" in inputs:\n    # --- FIX IS HERE ---\n    # Define the target language and get its token ID\n    tgt_lang = \"pan_Guru\"\n    forced_bos_token_id = tokenizer.convert_tokens_to_ids(f\"<2{tgt_lang}>\")\n    # -------------------\n    \n    with torch.no_grad():\n        # Pass the token ID to the generate function\n        outputs = model.generate(\n            **inputs, \n            num_beams=5, \n            max_length=256,\n            forced_bos_token_id=forced_bos_token_id  # <--- THIS FIXES THE ERROR\n        )\n\n    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    post = ip.postprocess_batch(decoded, lang=\"pan_Guru\")\n\n    print(\"\\nDecoded:\", decoded)\n    print(\"Postprocessed:\", post)\n    print(\"\\nTarget (for comparison):\", sample_tgt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:08.314155Z","iopub.execute_input":"2025-10-03T06:19:08.314376Z","iopub.status.idle":"2025-10-03T06:19:10.513031Z","shell.execute_reply.started":"2025-10-03T06:19:08.314359Z","shell.execute_reply":"2025-10-03T06:19:10.512245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize a list to store the results\nresults_data = []\n\n# Loop through all ordered pairs of your LANGS (excluding same-source/target)\nfor src in LANGS:\n    for tgt in LANGS:\n        if src == tgt:\n            continue\n\n        print(f\"\\n--- Evaluating direction: {src} -> {tgt} ---\")\n        try:\n            score = evaluate_direction(src, tgt, in22_gen_dataset)\n            results_data.append({\n                \"Source\": src,\n                \"Target\": tgt,\n                \"Reproduced chrF++\": round(score, 1)\n            })\n        except Exception as e:\n            print(f\"An error occurred during {src} -> {tgt}: {e}\")\n            results_data.append({\n                \"Source\": src,\n                \"Target\": tgt,\n                \"Reproduced chrF++\": \"Error\"\n            })\n\n# Convert the results list to a DataFrame\nreproduced_df = pd.DataFrame(results_data)\n\nprint(\"\\n--- Full Experiment Complete ---\")\nreproduced_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:10.513743Z","iopub.execute_input":"2025-10-03T06:19:10.514032Z","iopub.status.idle":"2025-10-03T07:21:19.699968Z","shell.execute_reply.started":"2025-10-03T06:19:10.514008Z","shell.execute_reply":"2025-10-03T07:21:19.699396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Calculate average scores for each language (xx->lang and lang->xx)\ndef calculate_average_scores(results_df):\n    avg_scores = {}\n    \n    for lang in LANGS:\n        # xx->lang: all sources to this target language\n        xx_to_lang_scores = results_df[results_df['Target'] == lang]['Reproduced chrF++'].tolist()\n        \n        # lang->xx: this source to all target languages  \n        lang_to_xx_scores = results_df[results_df['Source'] == lang]['Reproduced chrF++'].tolist()\n        \n        avg_scores[lang] = {\n            'xx-lang': np.mean(xx_to_lang_scores) if xx_to_lang_scores else 0,\n            'lang-xx': np.mean(lang_to_xx_scores) if lang_to_xx_scores else 0\n        }\n    \n    return avg_scores\n\n# Calculate our reproduced average scores\nreproduced_avg_scores = calculate_average_scores(reproduced_df)\n\n# Create comparison table with paper scores from the image\ncomparison_data = []\nfor lang in LANGS:\n    # Paper scores from the table image (IT2-Dist-M2M columns)\n    paper_xx_lang = {\n        'hin_Deva': 47.1, 'pan_Guru': 40.9, 'tam_Taml': 42.6, \n        'ben_Beng': 43.2, 'mar_Deva': 41.5, 'tel_Telu': 42.9\n    }[lang]\n    \n    paper_lang_xx = {\n        'hin_Deva': 42.3, 'pan_Guru': 39.1, 'tam_Taml': 39.3, \n        'ben_Beng': 41.2, 'mar_Deva': 42.4, 'tel_Telu': 41.9\n    }[lang]\n    \n    comparison_data.append({\n        'Language': lang,\n        'Paper xx-lang': paper_xx_lang,\n        'Reproduced xx-lang': round(reproduced_avg_scores[lang]['xx-lang'], 1),\n        'Paper lang-xx': paper_lang_xx,\n        'Reproduced lang-xx': round(reproduced_avg_scores[lang]['lang-xx'], 1)\n    })\n\n# Create final comparison DataFrame\ncomparison_df = pd.DataFrame(comparison_data)\n\n# Calculate differences\ncomparison_df['Diff xx-lang'] = comparison_df['Reproduced xx-lang'] - comparison_df['Paper xx-lang']\ncomparison_df['Diff lang-xx'] = comparison_df['Reproduced lang-xx'] - comparison_df['Paper lang-xx']\n\nprint(\"Comparison of Average Scores (IT2-Dist-M2M)\")\nprint(\"=\" * 80)\ndisplay(comparison_df)\n\n# Calculate overall statistics\nprint(f\"\\nOverall Statistics:\")\nprint(f\"Average xx-lang difference: {comparison_df['Diff xx-lang'].mean():.1f}\")\nprint(f\"Average lang-xx difference: {comparison_df['Diff lang-xx'].mean():.1f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T07:33:43.474040Z","iopub.execute_input":"2025-10-03T07:33:43.474335Z","iopub.status.idle":"2025-10-03T07:33:43.498720Z","shell.execute_reply.started":"2025-10-03T07:33:43.474314Z","shell.execute_reply":"2025-10-03T07:33:43.497946Z"}},"outputs":[],"execution_count":null}]}