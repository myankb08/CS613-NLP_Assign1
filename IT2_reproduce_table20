{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install essential libraries for deep learning, model loading, and evaluation\n!pip install torch --quiet\n!pip install transformers==4.53.2 --quiet\n!pip install datasets==2.18.0 --quiet\n!pip install evaluate==0.4.1 --quiet\n!pip install sacrebleu==2.4.2 --quiet\n!pip install pandas --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:16:50.211093Z","iopub.execute_input":"2025-10-03T06:16:50.211686Z","iopub.status.idle":"2025-10-03T06:18:29.353828Z","shell.execute_reply.started":"2025-10-03T06:16:50.211660Z","shell.execute_reply":"2025-10-03T06:18:29.352858Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.2.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install the custom toolkit required for IndicTrans2 pre-processing and post-processing\n!pip install indictranstoolkit --quiet","metadata":{"execution":{"iopub.status.busy":"2025-10-03T06:18:29.354985Z","iopub.execute_input":"2025-10-03T06:18:29.355318Z","iopub.status.idle":"2025-10-03T06:18:33.667958Z","shell.execute_reply.started":"2025-10-03T06:18:29.355282Z","shell.execute_reply":"2025-10-03T06:18:33.667231Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.1/546.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# Access the stored Hugging Face token from Kaggle Secrets\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\n# Programmatically log in to Hugging Face\nlogin(token=hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:18:33.668867Z","iopub.execute_input":"2025-10-03T06:18:33.669092Z","iopub.status.idle":"2025-10-03T06:18:34.347645Z","shell.execute_reply.started":"2025-10-03T06:18:33.669069Z","shell.execute_reply":"2025-10-03T06:18:34.347093Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\n# Define the device for computation (GPU if available, otherwise CPU)\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nLANGS = [\"hin_Deva\", \"pan_Guru\", \"tam_Taml\", \"ben_Beng\", \"mar_Deva\", \"tel_Telu\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:18:34.349401Z","iopub.execute_input":"2025-10-03T06:18:34.349591Z","iopub.status.idle":"2025-10-03T06:18:37.588973Z","shell.execute_reply.started":"2025-10-03T06:18:34.349575Z","shell.execute_reply":"2025-10-03T06:18:37.588393Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\nMODEL_NAME = \"ai4bharat/indictrans2-indic-indic-dist-320M\"\n\n# Load the tokenizer\n# trust_remote_code is required for custom tokenization logic\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n\n# Load the model\n# trust_remote_code is required for custom model architecture\n# torch_dtype=torch.float16 uses half-precision for memory efficiency and speed\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    MODEL_NAME,\n    trust_remote_code=True,\n).to(DEVICE)\n\nmodel.eval() # Set the model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:18:37.589637Z","iopub.execute_input":"2025-10-03T06:18:37.589942Z","iopub.status.idle":"2025-10-03T06:19:05.781716Z","shell.execute_reply.started":"2025-10-03T06:18:37.589925Z","shell.execute_reply":"2025-10-03T06:19:05.781077Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0802580f93b4ab0aa5c566fd1270ca0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenization_indictrans.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73d143207e842ca99789351077efee6"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- tokenization_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"dict.SRC.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b360a9ae6a834f92910becfb2d14822b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dict.TGT.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4db33f54d24750a9fce3ad7247826c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.SRC:   0%|          | 0.00/3.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38375cf311454eea96dc16c895a86afe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e96b36c848949609c3643ea02a41231"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddb29aed07d645bb9ff4c739473cd26e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_indictrans.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02908b983b7046d0856cf080466422d3"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- configuration_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_indictrans.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"643af2367c534a3888d10f21b46b8ed7"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-indic-indic-dist-320M:\n- modeling_indictrans.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n2025-10-03 06:18:48.884934: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759472329.074747      75 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759472329.131037      75 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96f6fa3524b244a3913ea8729b444fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d586bf2d7c9b4444bca0d9ffb9380ec5"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"IndicTransForConditionalGeneration(\n  (model): IndicTransModel(\n    (encoder): IndicTransEncoder(\n      (embed_tokens): Embedding(122706, 512, padding_idx=1)\n      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-17): 18 x IndicTransEncoderLayer(\n          (self_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): IndicTransDecoder(\n      (embed_tokens): Embedding(122672, 512, padding_idx=1)\n      (embed_positions): IndicTransSinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-17): 18 x IndicTransDecoderLayer(\n          (self_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): IndicTransAttention(\n            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (layernorm_embedding): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=122672, bias=False)\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from IndicTransToolkit.processor import IndicProcessor\n\n# Instantiate the processor for inference tasks\nip = IndicProcessor(inference=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:05.782433Z","iopub.execute_input":"2025-10-03T06:19:05.782941Z","iopub.status.idle":"2025-10-03T06:19:06.298627Z","shell.execute_reply.started":"2025-10-03T06:19:05.782921Z","shell.execute_reply":"2025-10-03T06:19:06.298032Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the 'test' split of the IN22-Gen dataset in the 'all' configuration\n# This provides a single table with all language pairs aligned by sentence ID\nin22_gen_dataset = load_dataset(\"ai4bharat/IN22-Gen\", split=\"test\")\n\n# Display the first example to inspect the structure\nprint(\"Dataset loaded. Example entry:\")\nprint(in22_gen_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:06.299374Z","iopub.execute_input":"2025-10-03T06:19:06.299586Z","iopub.status.idle":"2025-10-03T06:19:08.097706Z","shell.execute_reply.started":"2025-10-03T06:19:06.299569Z","shell.execute_reply":"2025-10-03T06:19:08.097110Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/7.71k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3e0f3ee0eba42eea1e2ebc96ef0ca53"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|██████████| 4.34M/4.34M [00:00<00:00, 20.4MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b46dbdd26c93448b8515155d9a3f8c59"}},"metadata":{}},{"name":"stdout","text":"Dataset loaded. Example entry:\nDataset({\n    features: ['context', 'source', 'url', 'domain', 'num_words', 'bucket', 'asm_Beng', 'ben_Beng', 'brx_Deva', 'doi_Deva', 'eng_Latn', 'gom_Deva', 'guj_Gujr', 'hin_Deva', 'kan_Knda', 'kas_Arab', 'mai_Deva', 'mal_Mlym', 'mar_Deva', 'mni_Mtei', 'npi_Deva', 'ory_Orya', 'pan_Guru', 'san_Deva', 'sat_Olck', 'snd_Deva', 'tam_Taml', 'tel_Telu', 'urd_Arab'],\n    num_rows: 1024\n})\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import math\nfrom tqdm.notebook import tqdm\n\ndef translate_batch(sentences, src_lang, tgt_lang, batch_size=16):\n    translations = []\n    for i in tqdm(range(0, len(sentences), batch_size), desc=f\"Translating {src_lang} -> {tgt_lang}\"):\n        batch = sentences[i:i+batch_size]\n\n        if not batch or all(s is None or str(s).strip() == \"\" for s in batch):\n            continue\n\n        # Preprocess\n        preprocessed_batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n        if preprocessed_batch is None or len(preprocessed_batch) == 0:\n            print(f\"⚠️ Preprocessing returned None/empty for {src_lang}->{tgt_lang}\")\n            continue\n\n        # Tokenize\n        inputs = tokenizer(\n            preprocessed_batch,\n            padding=True,\n            truncation=True,\n            return_tensors=\"pt\"\n        ).to(DEVICE)\n\n        forced_bos_token_id = tokenizer.convert_tokens_to_ids(f\"<2{tgt_lang}>\")\n        \n        # Generate\n        with torch.no_grad():\n            generated_tokens = model.generate(\n                **inputs,\n                num_beams=5,\n                max_length=256,\n                forced_bos_token_id=forced_bos_token_id\n            )\n\n        # Decode\n        decoded = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n\n        # Postprocess safely\n        try:\n            postprocessed = ip.postprocess_batch(decoded, lang=tgt_lang)\n            if postprocessed is None:\n                raise ValueError(\"postprocess_batch returned None\")\n        except Exception as e:\n            print(f\"⚠️ Postprocessing failed for {src_lang}->{tgt_lang}: {e}\")\n            postprocessed = decoded  # fallback\n\n        translations.extend(postprocessed)\n\n    return translations\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:08.098458Z","iopub.execute_input":"2025-10-03T06:19:08.099015Z","iopub.status.idle":"2025-10-03T06:19:08.106305Z","shell.execute_reply.started":"2025-10-03T06:19:08.098995Z","shell.execute_reply":"2025-10-03T06:19:08.105536Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import evaluate\ndef evaluate_direction(src_lang, tgt_lang, dataset, num_samples=200):\n    \"\"\"\n    Evaluate translation performance from src_lang -> tgt_lang\n    using chrF++ on a subset of the dataset.\n    \"\"\"\n    src_sentences = dataset[src_lang][:num_samples]\n    tgt_sentences = dataset[tgt_lang][:num_samples]\n\n    # Translate\n    preds = translate_batch(src_sentences, src_lang, tgt_lang)\n\n    # Ensure preds is a flat list of strings\n    preds = [p if isinstance(p, str) else \"\" for p in preds]\n\n    if len(preds) == 0:\n        print(f\"⚠️ No predictions produced for {src_lang}->{tgt_lang}\")\n        return None\n\n    from sacrebleu.metrics import CHRF\n    chrf = CHRF(word_order=2)  # chrF++\n    score = chrf.corpus_score(preds, [tgt_sentences]).score\n    return score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:08.106934Z","iopub.execute_input":"2025-10-03T06:19:08.107129Z","iopub.status.idle":"2025-10-03T06:19:08.313453Z","shell.execute_reply.started":"2025-10-03T06:19:08.107114Z","shell.execute_reply":"2025-10-03T06:19:08.312831Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Pick 5 sentences for testing\nsample_src = in22_gen_dataset[\"hin_Deva\"][:5]\nsample_tgt = in22_gen_dataset[\"pan_Guru\"][:5]\n\nprint(\"RAW source examples:\", sample_src)\n\n# Step 1: Preprocess\npreprocessed = ip.preprocess_batch(sample_src, src_lang=\"hin_Deva\", tgt_lang=\"pan_Guru\")\nprint(\"\\nAfter preprocess:\", preprocessed)\n\n# Step 2: Tokenize\ninputs = tokenizer(\n    preprocessed,\n    padding=True,\n    truncation=True,\n    return_tensors=\"pt\"\n).to(DEVICE)\n\nprint(\"\\nTokenizer output keys:\", inputs.keys())\nprint(\"Shape of input_ids:\", inputs[\"input_ids\"].shape if \"input_ids\" in inputs else \"MISSING\")\n\n# Step 3: Generate (only if inputs look good)\nif \"input_ids\" in inputs:\n    # --- FIX IS HERE ---\n    # Define the target language and get its token ID\n    tgt_lang = \"pan_Guru\"\n    forced_bos_token_id = tokenizer.convert_tokens_to_ids(f\"<2{tgt_lang}>\")\n    # -------------------\n    \n    with torch.no_grad():\n        # Pass the token ID to the generate function\n        outputs = model.generate(\n            **inputs, \n            num_beams=5, \n            max_length=256,\n            forced_bos_token_id=forced_bos_token_id  # <--- THIS FIXES THE ERROR\n        )\n\n    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n    post = ip.postprocess_batch(decoded, lang=\"pan_Guru\")\n\n    print(\"\\nDecoded:\", decoded)\n    print(\"Postprocessed:\", post)\n    print(\"\\nTarget (for comparison):\", sample_tgt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:08.314155Z","iopub.execute_input":"2025-10-03T06:19:08.314376Z","iopub.status.idle":"2025-10-03T06:19:10.513031Z","shell.execute_reply.started":"2025-10-03T06:19:08.314359Z","shell.execute_reply":"2025-10-03T06:19:10.512245Z"}},"outputs":[{"name":"stdout","text":"RAW source examples: ['सेवा संबंधी लोगों के लिए भेष कई गुणों का संयोजन है, जैसे कि उनके जूते, कपड़े, टाई, आभूषण, केश शैली, मेक-अप, घड़ी, कॉस्मेटिक, इत्र, आदि।', 'महाराष्ट्र के औरंगाबाद जिले में स्थित अजंता में उन्तीस चैत्य और विहार गुफाएँ हैं जो पहली शताब्दी ई.पू. से ले कर पाँचवीं शताब्दी ईस्वी तक की मूर्तियों तथा चित्रकारियों से सुसज्जित हैं।', 'विस्तार का असर बनाते हुए, शरीर का रंग बाहरी रेखा में घुल-मिल जाता है।', 'अशोक ने व्यापक रूप से मूर्तियों और शानदार स्मारकों को बनाने के लिए पत्थर का प्रयोग करना शुरू किया, जबकि उससे पहले पारंपरिक रूप से लकड़ी और मिट्टी का प्रयोग किया जाता है।', 'महाराष्ट्र के इस स्वादिष्ट और प्रसिद्ध व्यंजन में आलुओं में मसाले को मिलाकर, बेसन के घोल की परत लगाकर, उसे अच्छी तरह से तल कर बनाया जाता है।']\n\nAfter preprocess: ['hin_Deva pan_Guru सेवा संबंधी लोगों के लिए भेष कई गुणों का संयोजन है , जैसे कि उनके जूते , कपड़े , टाई , आभूषण , केश शैली , मेक - अप , घड़ी , कॉस्मेटिक , इत्र , आदि ।', 'hin_Deva pan_Guru महाराष्ट्र के औरंगाबाद जिले में स्थित अजंता में उन्तीस चैत्य और विहार गुफाएँ हैं जो पहली शताब्दी ई . पू . से ले कर पाँचवीं शताब्दी ईस्वी तक की मूर्तियों तथा चित्रकारियों से सुसज्जित हैं ।', 'hin_Deva pan_Guru विस्तार का असर बनाते हुए , शरीर का रंग बाहरी रेखा में घुल - मिल जाता है ।', 'hin_Deva pan_Guru अशोक ने व्यापक रूप से मूर्तियों और शानदार स्मारकों को बनाने के लिए पत्थर का प्रयोग करना शुरू किया , जबकि उससे पहले पारंपरिक रूप से लकड़ी और मिट्टी का प्रयोग किया जाता है ।', 'hin_Deva pan_Guru महाराष्ट्र के इस स्वादिष्ट और प्रसिद्ध व्यंजन में आलुओं में मसाले को मिलाकर , बेसन के घोल की परत लगाकर , उसे अच्छी तरह से तल कर बनाया जाता है ।']\n\nTokenizer output keys: KeysView({'input_ids': tensor([[    1,     1,     1,     8,    30,   927,  6182,   372,    12,    58,\n         57509,   368,  1502,   101,    41,  6947,    11,     6,  1284,    39,\n           521, 32135,     6, 14655,     6, 24783,     6, 39832,     6, 18820,\n          4954,     6,  7278,    22,   935,     6, 27826,     6,  4006,   137,\n         20403,     6, 18315,     6,  2506,     7,     2],\n        [    8,    30,  1309,    12, 37214,  3375,    19,  1482,  4587,  5833,\n            19,   291,   919,  5495,  7075,  4574,    26, 21597, 38997,  6327,\n            43,    99,  1991, 11540,    42,     5,   987,     5,    29,   487,\n            59,  5252,  4386, 11540, 67698,   275,    21, 22194,   475,   655,\n         31771,   475,    29, 32264,    43,     7,     2],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     1,     1,     1,     1,     8,    30,  3450,    41,\n          2276, 19610,   335,     6,   958,    41,   848, 13130,  6957,    19,\n         48240,    22,  1149,   674,    11,     7,     2],\n        [    1,     1,     1,     1,     1,     1,     1,     8,    30,  7995,\n            36,  3164,   216,    29, 22194,   475,    26,  3425, 31027,  2149,\n            33,  2051,    12,    58, 18455,    41,  1626,   338,   780,    92,\n             6,  1695,  4579,   412, 15532,   216,    29, 29992,    26, 23970,\n            41,  1626,    92,   674,    11,     7,     2],\n        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n             1,     1,     8,    30,  1309,    12,    51, 12464,    26,  2329,\n         34474,    19, 36411,   668,    19, 25918,    33, 21774,     6, 46810,\n            12, 45472,    21,  3209, 24685,     6,   884,  2091,   472,    29,\n          1796,    59,  3812,   674,    11,     7,     2]], device='cuda:0'), 'attention_mask': tensor([[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n       device='cuda:0')})\nShape of input_ids: torch.Size([5, 47])\n\nDecoded: ['विੱच स़ामल लोकां लई भेस कई गुणां दा सुमेल है, जिवें कि उन्हां दे जुੱते, कੱपड़े, टाई, गहिणे, वाल सटाईल, मेक - अੱप, घड़ी, कासमैटिक, अतर आदि ।', 'विੱच 19 चैतीआ अते विहार गुफावां हन जो पहिली सदी बी. सी. तों पੰजवीं सदी सी. ई. तੱक दीआं मूरतीआं अते चिੱतरकारां नाल लैस हन, जो महारास़टर दे औरੰगाबाद ज़िल्हे विੱच सथित हन ।', 'दा प्रभाव बणाउंदे होए, सरीर दा रੰग बाहरी रेखा विੱच घुल जांदा है ।', 'ने मूरतीआं अते स़ानदार समारक बणाउण लई वੱडे पੱधर उੱते पੱथर दी वरतों करनी स़ुरू कर दिੱती, जदों कि इस तों पहिलां रवाइती तौर उੱते लੱकड़ अते मिੱटी दी वरतों कीती जांदी सी ।', 'विੱच मसाले नूੰ मिला के, बेसन दे घोल दी परत पा के, इस महारास़टर दे सुआदी अते प्रसिੱध पकवान नूੰ चੰगी तर्हां तल के बणाइआ जांदा है ।']\nPostprocessed: ['ਵਿੱਚ ਸ਼ਾਮਲ ਲੋਕਾਂ ਲਈ ਭੇਸ ਕਈ ਗੁਣਾਂ ਦਾ ਸੁਮੇਲ ਹੈ, ਜਿਵੇਂ ਕਿ ਉਨ੍ਹਾਂ ਦੇ ਜੁੱਤੇ, ਕੱਪਡ਼ੇ, ਟਾਈ, ਗਹਿਣੇ, ਵਾਲ ਸਟਾਈਲ, ਮੇਕ-ਅੱਪ, ਘਡ਼ੀ, ਕਾਸਮੈਟਿਕ, ਅਤਰ ਆਦਿ।', 'ਵਿੱਚ 19 ਚੈਤੀਆ ਅਤੇ ਵਿਹਾਰ ਗੁਫਾਵਾਂ ਹਨ ਜੋ ਪਹਿਲੀ ਸਦੀ ਬੀ. ਸੀ. ਤੋਂ ਪੰਜਵੀਂ ਸਦੀ ਸੀ. ਈ. ਤੱਕ ਦੀਆਂ ਮੂਰਤੀਆਂ ਅਤੇ ਚਿੱਤਰਕਾਰਾਂ ਨਾਲ ਲੈਸ ਹਨ, ਜੋ ਮਹਾਰਾਸ਼ਟਰ ਦੇ ਔਰੰਗਾਬਾਦ ਜ਼ਿਲ੍ਹੇ ਵਿੱਚ ਸਥਿਤ ਹਨ।', 'ਦਾ ਪ੍ਰਭਾਵ ਬਣਾਉਂਦੇ ਹੋਏ, ਸਰੀਰ ਦਾ ਰੰਗ ਬਾਹਰੀ ਰੇਖਾ ਵਿੱਚ ਘੁਲ ਜਾਂਦਾ ਹੈ।', 'ਨੇ ਮੂਰਤੀਆਂ ਅਤੇ ਸ਼ਾਨਦਾਰ ਸਮਾਰਕ ਬਣਾਉਣ ਲਈ ਵੱਡੇ ਪੱਧਰ ਉੱਤੇ ਪੱਥਰ ਦੀ ਵਰਤੋਂ ਕਰਨੀ ਸ਼ੁਰੂ ਕਰ ਦਿੱਤੀ, ਜਦੋਂ ਕਿ ਇਸ ਤੋਂ ਪਹਿਲਾਂ ਰਵਾਇਤੀ ਤੌਰ ਉੱਤੇ ਲੱਕਡ਼ ਅਤੇ ਮਿੱਟੀ ਦੀ ਵਰਤੋਂ ਕੀਤੀ ਜਾਂਦੀ ਸੀ।', 'ਵਿੱਚ ਮਸਾਲੇ ਨੂੰ ਮਿਲਾ ਕੇ, ਬੇਸਨ ਦੇ ਘੋਲ ਦੀ ਪਰਤ ਪਾ ਕੇ, ਇਸ ਮਹਾਰਾਸ਼ਟਰ ਦੇ ਸੁਆਦੀ ਅਤੇ ਪ੍ਰਸਿੱਧ ਪਕਵਾਨ ਨੂੰ ਚੰਗੀ ਤਰ੍ਹਾਂ ਤਲ ਕੇ ਬਣਾਇਆ ਜਾਂਦਾ ਹੈ।']\n\nTarget (for comparison): ['ਇਕ ਵਿਅਕਤੀ ਦਾ ਪਹਿਰਾਵਾ ਜੀਵੇਂ ਕਿ ਉਸ ਦੇ ਜੁੱਤੇ, ਕੱਪੜੇ, ਨੈਕਟਾਈ,ਆਭੂਸ਼ਣ, ਬਾਲ ਬਣਾਉਣ ਦਾ ਤਰੀਕਾ, ਮੈਕ-ਅੱਪ, ਘੜੀ, ਅਤਰ ਆਦੀ ਉਸ ਦਿਆਂ ਵਿਸ਼ੇਸ਼ਤਵਾਂ ਦਰਸਾਉਂਦਾ ਹੈ I', 'ਮਹਾਰਾਸ਼ਟਰਾ ਦੇ ਔਰੰਗਾਬਾਦ ਜਿਲ੍ਹੇ ਵਿੱਚ ਸਥਿਤ ਅਜੰਤਾ ਵਿੱਚ ਉਨੱਤੀ ਕੇਟਿਆ ਅਤੇ ਵਿਹਾਰਾ ਗੁਫ਼ਾਵਾ ਹਨ ਜੋਂ ਪਿਹਲੀ ਸਦੀ ਤੋਂ ਲੈ ਕੇ ਪੰਜਵੀ ਸਦੀ ਤੱਕ ਦੀਆਂ ਮੂਰਤੀਆਂ ਅਤੇ ਚਿਤੱਰਕਾਰੀ ਨਾਲ ਸਜਿਆ ਹੋਈਆਂ ਹਨ I', 'ਸ਼ਰੀਰ ਦਾ ਰੰਗ ਬਾਹਰਲੀ ਸ਼੍ਰੇਣੀ ਨਾਲ ਜੁੜ ਕੇ ਇੱਕ ਵੱਡੇ ਅਕਾਰ ਦੀ ਭਾਂਤ ਦਿੰਦਾ ਹੈ I', 'ਅਸ਼ੋਕਾ ਨੇ ਵੱਧ-ਚੜ ਕੇ ਪਧੱਰ ਦਾ ਪ੍ਰਯੋਗ ਕਰਵੇ ਮੂਰਤੀਆਂ ਅਤੇ ਹੋਰ ਸਮਾਰਕ ਬਣਵਾਣ ਦੇ ਲਈ, ਇਸ ਤੋਂ ਪਹਿਲਾਂ ਸਾਰੀਆਂ ਇਮਾਰਤਾਂ ਲੱਕੜ ਅਤੇ ਮਿੱਟੀ ਦਿਆਂ ਬਣਦੀਆਂ ਸਨ I', 'ਮਹਾਰਾਸ਼ਟਰ ਦੀ ਇਹ ਜ਼ਾਇਕੇਦਾਰ ਅਤੇ ਮਸ਼ਹੂਰ ਪਕਵਾਨ ਬਣਾਉਨਣ ਲਈ ਆਲੂਆਂ ਨੂੰ ਮਸਲਿਆ ਨਾਲ ਰਲਾ ਕੇ ਫ਼ੇਰ ਬੇਸਨ ਦੀ ਇਕ ਪਰਤ ਚੜਾ ਕੇ ਤਲਿਆ ਜਾਂਦਾ ਹੈ I']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Initialize a list to store the results\nresults_data = []\n\n# Loop through all ordered pairs of your LANGS (excluding same-source/target)\nfor src in LANGS:\n    for tgt in LANGS:\n        if src == tgt:\n            continue\n\n        print(f\"\\n--- Evaluating direction: {src} -> {tgt} ---\")\n        try:\n            score = evaluate_direction(src, tgt, in22_gen_dataset)\n            results_data.append({\n                \"Source\": src,\n                \"Target\": tgt,\n                \"Reproduced chrF++\": round(score, 1)\n            })\n        except Exception as e:\n            print(f\"An error occurred during {src} -> {tgt}: {e}\")\n            results_data.append({\n                \"Source\": src,\n                \"Target\": tgt,\n                \"Reproduced chrF++\": \"Error\"\n            })\n\n# Convert the results list to a DataFrame\nreproduced_df = pd.DataFrame(results_data)\n\nprint(\"\\n--- Full Experiment Complete ---\")\nreproduced_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T06:19:10.513743Z","iopub.execute_input":"2025-10-03T06:19:10.514032Z","iopub.status.idle":"2025-10-03T07:21:19.699968Z","shell.execute_reply.started":"2025-10-03T06:19:10.514008Z","shell.execute_reply":"2025-10-03T07:21:19.699396Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating direction: hin_Deva -> pan_Guru ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating hin_Deva -> pan_Guru:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c58c6829634999b3a048d1eabbc612"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: hin_Deva -> tam_Taml ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating hin_Deva -> tam_Taml:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20337e4131964a91bd821d0dcad86833"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: hin_Deva -> ben_Beng ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating hin_Deva -> ben_Beng:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65881114178c43f2ad82ef0d70095374"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: hin_Deva -> mar_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating hin_Deva -> mar_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e081e2e5d23499a9b556a0acae04c7c"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: hin_Deva -> tel_Telu ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating hin_Deva -> tel_Telu:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c1eb2bb83b4052b92e53945b92d612"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: pan_Guru -> hin_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating pan_Guru -> hin_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4bfcb0ce0904f1b9939458ec54f0667"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: pan_Guru -> tam_Taml ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating pan_Guru -> tam_Taml:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86abc1861e6e4bf281018474c89c7f0c"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: pan_Guru -> ben_Beng ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating pan_Guru -> ben_Beng:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e06ecda730f4fc2a6f36f14d2ac23a4"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: pan_Guru -> mar_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating pan_Guru -> mar_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af56976366d407fbc1013f6c678f9c8"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: pan_Guru -> tel_Telu ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating pan_Guru -> tel_Telu:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3feaf70bceb64f7dac741ef43840fdab"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tam_Taml -> hin_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tam_Taml -> hin_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96036d409ed64c7d9975b838a0f814bd"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tam_Taml -> pan_Guru ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tam_Taml -> pan_Guru:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"475527622e0d402d84db1d4dccbd0c41"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tam_Taml -> ben_Beng ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tam_Taml -> ben_Beng:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eca4824f2076433ebcf4938aafa5facc"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tam_Taml -> mar_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tam_Taml -> mar_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eab477c623a4046a39366a2ab59e092"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tam_Taml -> tel_Telu ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tam_Taml -> tel_Telu:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3e75e1dd874dd48f1265207efbde8b"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: ben_Beng -> hin_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating ben_Beng -> hin_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"848015ccc4e945a1b9f6880919aac2f3"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: ben_Beng -> pan_Guru ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating ben_Beng -> pan_Guru:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91a9c79cab014088a0971f1dd78f621f"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: ben_Beng -> tam_Taml ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating ben_Beng -> tam_Taml:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88a3e5eb0ac54be7a9566090a37d3485"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: ben_Beng -> mar_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating ben_Beng -> mar_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d96c67b33c94c8db0b5a23fea03e4fa"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: ben_Beng -> tel_Telu ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating ben_Beng -> tel_Telu:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0d2da3289504a21b43951b1853964e7"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: mar_Deva -> hin_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating mar_Deva -> hin_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2967acabc0e4d4384a3a34d98c59879"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: mar_Deva -> pan_Guru ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating mar_Deva -> pan_Guru:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5377464506d48328eb875982a84cdae"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: mar_Deva -> tam_Taml ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating mar_Deva -> tam_Taml:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41c5b495710401084d31d4974256ffa"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: mar_Deva -> ben_Beng ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating mar_Deva -> ben_Beng:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18d3f98af0244d7ebacd3bb77726f0a2"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: mar_Deva -> tel_Telu ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating mar_Deva -> tel_Telu:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221522eab494476690f69f3c2ed43cc4"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tel_Telu -> hin_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tel_Telu -> hin_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42de780a0014416d8785f72256352fd8"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tel_Telu -> pan_Guru ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tel_Telu -> pan_Guru:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7866e4835884a7597112810fbf1b83f"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tel_Telu -> tam_Taml ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tel_Telu -> tam_Taml:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35804e2d4e2e4f24be0d241b0eb5488d"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tel_Telu -> ben_Beng ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tel_Telu -> ben_Beng:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af62873a01154f85a148d7f081f4125d"}},"metadata":{}},{"name":"stdout","text":"\n--- Evaluating direction: tel_Telu -> mar_Deva ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Translating tel_Telu -> mar_Deva:   0%|          | 0/13 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efdf111f0173497cbacb8295ac13f809"}},"metadata":{}},{"name":"stdout","text":"\n--- Full Experiment Complete ---\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"      Source    Target  Reproduced chrF++\n0   hin_Deva  pan_Guru               26.6\n1   hin_Deva  tam_Taml               32.7\n2   hin_Deva  ben_Beng               30.2\n3   hin_Deva  mar_Deva               32.8\n4   hin_Deva  tel_Telu               31.7\n5   pan_Guru  hin_Deva               28.9\n6   pan_Guru  tam_Taml               26.3\n7   pan_Guru  ben_Beng               22.8\n8   pan_Guru  mar_Deva               23.9\n9   pan_Guru  tel_Telu               24.0\n10  tam_Taml  hin_Deva               31.8\n11  tam_Taml  pan_Guru               23.9\n12  tam_Taml  ben_Beng               28.0\n13  tam_Taml  mar_Deva               29.7\n14  tam_Taml  tel_Telu               30.9\n15  ben_Beng  hin_Deva               32.6\n16  ben_Beng  pan_Guru               23.4\n17  ben_Beng  tam_Taml               30.9\n18  ben_Beng  mar_Deva               28.9\n19  ben_Beng  tel_Telu               29.1\n20  mar_Deva  hin_Deva               35.6\n21  mar_Deva  pan_Guru               25.0\n22  mar_Deva  tam_Taml               33.1\n23  mar_Deva  ben_Beng               29.9\n24  mar_Deva  tel_Telu               32.5\n25  tel_Telu  hin_Deva               34.0\n26  tel_Telu  pan_Guru               24.6\n27  tel_Telu  tam_Taml               33.5\n28  tel_Telu  ben_Beng               29.5\n29  tel_Telu  mar_Deva               31.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Target</th>\n      <th>Reproduced chrF++</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hin_Deva</td>\n      <td>pan_Guru</td>\n      <td>26.6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hin_Deva</td>\n      <td>tam_Taml</td>\n      <td>32.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hin_Deva</td>\n      <td>ben_Beng</td>\n      <td>30.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hin_Deva</td>\n      <td>mar_Deva</td>\n      <td>32.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hin_Deva</td>\n      <td>tel_Telu</td>\n      <td>31.7</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>pan_Guru</td>\n      <td>hin_Deva</td>\n      <td>28.9</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>pan_Guru</td>\n      <td>tam_Taml</td>\n      <td>26.3</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>pan_Guru</td>\n      <td>ben_Beng</td>\n      <td>22.8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>pan_Guru</td>\n      <td>mar_Deva</td>\n      <td>23.9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>pan_Guru</td>\n      <td>tel_Telu</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>tam_Taml</td>\n      <td>hin_Deva</td>\n      <td>31.8</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>tam_Taml</td>\n      <td>pan_Guru</td>\n      <td>23.9</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>tam_Taml</td>\n      <td>ben_Beng</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>tam_Taml</td>\n      <td>mar_Deva</td>\n      <td>29.7</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>tam_Taml</td>\n      <td>tel_Telu</td>\n      <td>30.9</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>ben_Beng</td>\n      <td>hin_Deva</td>\n      <td>32.6</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ben_Beng</td>\n      <td>pan_Guru</td>\n      <td>23.4</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>ben_Beng</td>\n      <td>tam_Taml</td>\n      <td>30.9</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ben_Beng</td>\n      <td>mar_Deva</td>\n      <td>28.9</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ben_Beng</td>\n      <td>tel_Telu</td>\n      <td>29.1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>mar_Deva</td>\n      <td>hin_Deva</td>\n      <td>35.6</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>mar_Deva</td>\n      <td>pan_Guru</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>mar_Deva</td>\n      <td>tam_Taml</td>\n      <td>33.1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>mar_Deva</td>\n      <td>ben_Beng</td>\n      <td>29.9</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>mar_Deva</td>\n      <td>tel_Telu</td>\n      <td>32.5</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>tel_Telu</td>\n      <td>hin_Deva</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>tel_Telu</td>\n      <td>pan_Guru</td>\n      <td>24.6</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>tel_Telu</td>\n      <td>tam_Taml</td>\n      <td>33.5</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>tel_Telu</td>\n      <td>ben_Beng</td>\n      <td>29.5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>tel_Telu</td>\n      <td>mar_Deva</td>\n      <td>31.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import numpy as np\n\n# Calculate average scores for each language (xx->lang and lang->xx)\ndef calculate_average_scores(results_df):\n    avg_scores = {}\n    \n    for lang in LANGS:\n        # xx->lang: all sources to this target language\n        xx_to_lang_scores = results_df[results_df['Target'] == lang]['Reproduced chrF++'].tolist()\n        \n        # lang->xx: this source to all target languages  \n        lang_to_xx_scores = results_df[results_df['Source'] == lang]['Reproduced chrF++'].tolist()\n        \n        avg_scores[lang] = {\n            'xx-lang': np.mean(xx_to_lang_scores) if xx_to_lang_scores else 0,\n            'lang-xx': np.mean(lang_to_xx_scores) if lang_to_xx_scores else 0\n        }\n    \n    return avg_scores\n\n# Calculate our reproduced average scores\nreproduced_avg_scores = calculate_average_scores(reproduced_df)\n\n# Create comparison table with paper scores from the image\ncomparison_data = []\nfor lang in LANGS:\n    # Paper scores from the table image (IT2-Dist-M2M columns)\n    paper_xx_lang = {\n        'hin_Deva': 47.1, 'pan_Guru': 40.9, 'tam_Taml': 42.6, \n        'ben_Beng': 43.2, 'mar_Deva': 41.5, 'tel_Telu': 42.9\n    }[lang]\n    \n    paper_lang_xx = {\n        'hin_Deva': 42.3, 'pan_Guru': 39.1, 'tam_Taml': 39.3, \n        'ben_Beng': 41.2, 'mar_Deva': 42.4, 'tel_Telu': 41.9\n    }[lang]\n    \n    comparison_data.append({\n        'Language': lang,\n        'Paper xx-lang': paper_xx_lang,\n        'Reproduced xx-lang': round(reproduced_avg_scores[lang]['xx-lang'], 1),\n        'Paper lang-xx': paper_lang_xx,\n        'Reproduced lang-xx': round(reproduced_avg_scores[lang]['lang-xx'], 1)\n    })\n\n# Create final comparison DataFrame\ncomparison_df = pd.DataFrame(comparison_data)\n\n# Calculate differences\ncomparison_df['Diff xx-lang'] = comparison_df['Reproduced xx-lang'] - comparison_df['Paper xx-lang']\ncomparison_df['Diff lang-xx'] = comparison_df['Reproduced lang-xx'] - comparison_df['Paper lang-xx']\n\nprint(\"Comparison of Average Scores (IT2-Dist-M2M)\")\nprint(\"=\" * 80)\ndisplay(comparison_df)\n\n# Calculate overall statistics\nprint(f\"\\nOverall Statistics:\")\nprint(f\"Average xx-lang difference: {comparison_df['Diff xx-lang'].mean():.1f}\")\nprint(f\"Average lang-xx difference: {comparison_df['Diff lang-xx'].mean():.1f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-03T07:33:43.474040Z","iopub.execute_input":"2025-10-03T07:33:43.474335Z","iopub.status.idle":"2025-10-03T07:33:43.498720Z","shell.execute_reply.started":"2025-10-03T07:33:43.474314Z","shell.execute_reply":"2025-10-03T07:33:43.497946Z"}},"outputs":[{"name":"stdout","text":"Comparison of Average Scores (IT2-Dist-M2M)\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   Language  Paper xx-lang  Reproduced xx-lang  Paper lang-xx  \\\n0  hin_Deva           47.1                32.6           42.3   \n1  pan_Guru           40.9                24.7           39.1   \n2  tam_Taml           42.6                31.3           39.3   \n3  ben_Beng           43.2                28.1           41.2   \n4  mar_Deva           41.5                29.4           42.4   \n5  tel_Telu           42.9                29.6           41.9   \n\n   Reproduced lang-xx  Diff xx-lang  Diff lang-xx  \n0                30.8         -14.5         -11.5  \n1                25.2         -16.2         -13.9  \n2                28.9         -11.3         -10.4  \n3                29.0         -15.1         -12.2  \n4                31.2         -12.1         -11.2  \n5                30.6         -13.3         -11.3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Language</th>\n      <th>Paper xx-lang</th>\n      <th>Reproduced xx-lang</th>\n      <th>Paper lang-xx</th>\n      <th>Reproduced lang-xx</th>\n      <th>Diff xx-lang</th>\n      <th>Diff lang-xx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hin_Deva</td>\n      <td>47.1</td>\n      <td>32.6</td>\n      <td>42.3</td>\n      <td>30.8</td>\n      <td>-14.5</td>\n      <td>-11.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pan_Guru</td>\n      <td>40.9</td>\n      <td>24.7</td>\n      <td>39.1</td>\n      <td>25.2</td>\n      <td>-16.2</td>\n      <td>-13.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tam_Taml</td>\n      <td>42.6</td>\n      <td>31.3</td>\n      <td>39.3</td>\n      <td>28.9</td>\n      <td>-11.3</td>\n      <td>-10.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ben_Beng</td>\n      <td>43.2</td>\n      <td>28.1</td>\n      <td>41.2</td>\n      <td>29.0</td>\n      <td>-15.1</td>\n      <td>-12.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>mar_Deva</td>\n      <td>41.5</td>\n      <td>29.4</td>\n      <td>42.4</td>\n      <td>31.2</td>\n      <td>-12.1</td>\n      <td>-11.2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>tel_Telu</td>\n      <td>42.9</td>\n      <td>29.6</td>\n      <td>41.9</td>\n      <td>30.6</td>\n      <td>-13.3</td>\n      <td>-11.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nOverall Statistics:\nAverage xx-lang difference: -13.8\nAverage lang-xx difference: -11.8\n","output_type":"stream"}],"execution_count":14}]}